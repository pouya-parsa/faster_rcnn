{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faster_rcnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qdrDnvznfcxP",
        "SBigJLTRfZGa",
        "UhJD-BM2pir5",
        "ge4ZFmb0OGxP",
        "HBWpd4HIN0WD",
        "7om054x-N3xf",
        "1AQQn2bUagSy",
        "uUVyPrl7v0YW",
        "8gtPEwWobJ1V",
        "T7haPYHrMmbP",
        "PYki6lDX9aPY",
        "FFtmE4lJ9nOg",
        "qYpSvma60TJA",
        "v-tJngL8EZIE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72de22c7e1414d4d9f43ed98f3a5c819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c8e5cc37f2c414685a8f9b7786c710b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_35fbeb4ab281469386df3e404d2d9661",
              "IPY_MODEL_6ffd56f46f3a479db197899674ea3b86",
              "IPY_MODEL_f6183bd884884b578858c80198156ec5"
            ]
          }
        },
        "3c8e5cc37f2c414685a8f9b7786c710b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35fbeb4ab281469386df3e404d2d9661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_850dd669787d442796b72f4ed26dd59b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f264973b7b2742739b9beabe8046e255"
          }
        },
        "6ffd56f46f3a479db197899674ea3b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b9d08ba5eb14d0bbb55a562dbdadd75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7feba3239364f5a879a2782a1f9eec8"
          }
        },
        "f6183bd884884b578858c80198156ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa7f305001044c7dab15d49a8d80f6fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2000/2000 [00:27&lt;00:00, 71.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e91946182793490a8499da8f1d5ec34c"
          }
        },
        "850dd669787d442796b72f4ed26dd59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f264973b7b2742739b9beabe8046e255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b9d08ba5eb14d0bbb55a562dbdadd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7feba3239364f5a879a2782a1f9eec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa7f305001044c7dab15d49a8d80f6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e91946182793490a8499da8f1d5ec34c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "001b43024ae84c38a9f3ee68b586b532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_25de0b87967d4ea4896cf6fb28b1525e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91cfcde298854d62a0eab84c06c9de7d",
              "IPY_MODEL_b262a09a985448df90d1b0e107278895",
              "IPY_MODEL_55b2afaf15da4ecf821503e82118f6c2"
            ]
          }
        },
        "25de0b87967d4ea4896cf6fb28b1525e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91cfcde298854d62a0eab84c06c9de7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb8bc3554656456d9c77afb7afbe9d6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e7600704af44425879a084f3a145931"
          }
        },
        "b262a09a985448df90d1b0e107278895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_708ad591c8bd473d8eb252453ec9d2db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1979,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aaf1031a89ae431db5853f1077d19ffb"
          }
        },
        "55b2afaf15da4ecf821503e82118f6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9349dbceabe2447595fae8232be871a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1979 [00:01&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b4fbc393ae94a1b97bd43927a8af9a7"
          }
        },
        "eb8bc3554656456d9c77afb7afbe9d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e7600704af44425879a084f3a145931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "708ad591c8bd473d8eb252453ec9d2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aaf1031a89ae431db5853f1077d19ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9349dbceabe2447595fae8232be871a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b4fbc393ae94a1b97bd43927a8af9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiH2vmxgCR-7",
        "outputId": "9c3aad19-a8e1-46a1-d94a-a95ce1f17390"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ziH2lPCcMn"
      },
      "source": [
        "!mkdir \"/content/vos\"\n",
        "!sudo unzip \"/content/drive/MyDrive/vos/train.zip\" -d \"/content/vos\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MmRVh-yeFQ8"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nKnHnZnJb-rm",
        "outputId": "628b33c6-2a93-439d-8d57-3c44f2218a0f"
      },
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 1\n",
        "pos_ratio = 0.5\n",
        "n_sample = 256\n",
        "n_pos = pos_ratio * n_sample\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdrDnvznfcxP"
      },
      "source": [
        "## Visualize Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eorEvi5ZJk7"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "colors = [(255, 128, 0), (255, 255, 0), (128, 255, 0), (0, 255, 0), (0, 255, 255), (0, 0, 255), (255, 0, 255), (96, 96, 96)]\n",
        "\n",
        "def visualize(image_path, anchor_boxes, gt_boxes=None):\n",
        "\n",
        "  image = Image.open(image_path)\n",
        "  image = image.resize((800, 800))\n",
        "\n",
        "  image = np.array(image)\n",
        "  \n",
        "  if gt_boxes is not None:\n",
        "    for i_box, box in enumerate(gt_boxes):\n",
        "      \n",
        "      start_point = (int(box[0]), int(box[1]))\n",
        "      end_point = (int(box[2]), int(box[3]))\n",
        "      \n",
        "      cv2.rectangle(image, start_point, end_point, (255, 0, 0), 2)\n",
        "\n",
        "  for i_box, box in enumerate(anchor_boxes):\n",
        "    \n",
        "    start_point = (int(box[0]), int(box[1]))\n",
        "    end_point = (int(box[2]), int(box[3]))\n",
        "    color_index = i_box % len(colors) \n",
        "    cv2.rectangle(image, start_point, end_point, colors[color_index], 2)\n",
        "  \n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(image)\n",
        "  plt.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVIIIRdHZ5mn"
      },
      "source": [
        "## UNIT TEST\n",
        "# valid_index = get_valid_anchor_boxes(anchor_boxes)\n",
        "# visualize(\"/content/image.jpg\", anchor_boxes[valid_index][1000:1005], get_bounding_box(\"/content/image.jpg\", \"/content/label.png\"))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKN8RGo3JO_M"
      },
      "source": [
        "def visualize_a_box(image_path, box):\n",
        "  visualize(image_path, [box])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBigJLTRfZGa"
      },
      "source": [
        "## Generate Anchor Boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuEx7jXOxo6h"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDshGdCQTg9w"
      },
      "source": [
        "def gen_anchor_box_for_single_feature_map(center_X, center_Y, scales, ratios):\n",
        "  \n",
        "  # Anchor Boxes are generated in the format (x1, y1, x2, y2)\n",
        "  \n",
        "  k = 0\n",
        "  boxes = np.zeros((len(scales) * len(ratios), 4))\n",
        "\n",
        "  for ratio in ratios:\n",
        "    \n",
        "    for scale in scales:\n",
        "\n",
        "      W = scale * subsample * ratio\n",
        "      H = scale * subsample\n",
        "\n",
        "      x_left_top = center_X - (1/2) * W\n",
        "      y_left_top = center_Y - (1/2) * H\n",
        "\n",
        "      x_right_bottom = center_X + (1/2) * W\n",
        "      y_right_bottom = center_Y + (1/2) * H \n",
        "\n",
        "      boxes[k, 0] = x_left_top\n",
        "      boxes[k, 1] = y_left_top\n",
        "      boxes[k, 2] = x_right_bottom\n",
        "      boxes[k, 3] = y_right_bottom\n",
        "\n",
        "      k += 1\n",
        "\n",
        "  return boxes\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Zo-FEJYZK7"
      },
      "source": [
        "## UNIT TEST\n",
        "# gen_anchor_box_for_single_feature_map(400, 400, [8, 16, 32], [0.5, 1, 2]) # output has to be in shape of (3 * 3, 4)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVYG4qOdKEnu"
      },
      "source": [
        "subsample = 16\n",
        "scales = [8, 16, 32]\n",
        "ratios = [0.5, 1, 2]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abpYUVzNOORt"
      },
      "source": [
        "def generate_all_anchor_boxes():\n",
        "  \n",
        "  anchor_boxes = np.zeros((50, 50, len(scales) * len(ratios), 4)) \n",
        "  \n",
        "  # center_X, center_Y\n",
        "  for i, center_X in enumerate(np.arange(8, 16 * (50), 16 )):\n",
        "    for j, center_Y in enumerate(np.arange(8, 16 * (50), 16)):\n",
        "      anchor_boxes[i, j] = gen_anchor_box_for_single_feature_map(center_X, center_Y, scales, ratios)\n",
        "\n",
        "  return anchor_boxes.reshape(-1, 4)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIuv7CV5XoPR"
      },
      "source": [
        "anchor_boxes = generate_all_anchor_boxes()\n",
        "#anchor_boxes.shape"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhJD-BM2pir5"
      },
      "source": [
        "### Valid anchors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15QMn6JkpmdL"
      },
      "source": [
        "def get_valid_anchor_boxes(anchor_boxes):\n",
        "  # x1 and x2 have to in range (0, 800), same applies to y1, y2\n",
        "  inside_anchors_index = (anchor_boxes[:, 0] >= 0) & (anchor_boxes[:, 2] < 800) &\\\n",
        "  (anchor_boxes[:, 1] >= 0) & (anchor_boxes[:, 3] < 800)\n",
        "\n",
        "  # valid_anchor_boxes = anchor_boxes[inside_anchors_index]\n",
        "\n",
        "  return inside_anchors_index"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQzQKynOqh-N"
      },
      "source": [
        "# UNIT TEST\n",
        "# the exact number depends on the scales and ratios you used\n",
        "# (inside_anchors_index == True).sum() > 0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge4ZFmb0OGxP"
      },
      "source": [
        "## Compute IoU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8zITOdTaA2g"
      },
      "source": [
        "def compute_iou(box1, box2):\n",
        "  # assumeing boxes are in format (x1, y1, x2, y2)\n",
        "  inter = {}\n",
        "  inter[\"x_left_top\"] = max(box1[0], box2[0])\n",
        "  inter[\"y_left_top\"] = max(box1[1], box2[1])\n",
        "\n",
        "  inter[\"x_right_bottom\"] = min(box1[2], box2[2])\n",
        "  inter[\"y_right_bottom\"] = min(box1[3], box2[3])\n",
        "\n",
        "  if inter[\"x_left_top\"] < inter[\"x_right_bottom\"] and inter[\"y_left_top\"] < inter[\"y_right_bottom\"]: # there is a non-zero intersection  \n",
        "    iou_area = (inter[\"x_right_bottom\"] - inter[\"x_left_top\"]) * (inter[\"y_right_bottom\"] - inter[\"y_left_top\"])\n",
        "  else:\n",
        "    iou_area = 0\n",
        "\n",
        "  box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "  box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "  iou = iou_area / (box1_area + box2_area - iou_area)\n",
        "\n",
        "  return iou"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTbbGaX6vNpq"
      },
      "source": [
        "## UNIT TEST\n",
        "# box1 = [0, 0, 5, 5]\n",
        "# box2 = [5, 5, 10, 10]\n",
        "# box3 = [2.5, 2.5, 7.5, 7.5]\n",
        "\n",
        "# compute_iou(box1, box2) # it has to be zero\n",
        "# compute_iou(box1, box3) # ~ 0.14\n",
        "# compute_iou(box3, box1) # it's a symetric function so same 0.14"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBWpd4HIN0WD"
      },
      "source": [
        "## Get Bouning Box from Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OhiuzvtrWLY"
      },
      "source": [
        "def get_number_of_instances(mask_path):\n",
        "  \n",
        "  mask = Image.open(mask_path)\n",
        "  mask = np.array(mask)\n",
        "\n",
        "  return len(np.unique(mask))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gvTsO2TG1V8"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def get_bounding_box(mask_path):\n",
        "\n",
        "  mask = Image.open(mask_path)\n",
        "  \n",
        "  mask = mask.resize((800, 800))  # otherwise boxes don't place at right locations \n",
        "\n",
        "  mask = np.array(mask)\n",
        "\n",
        "  # mask is in shape of [H, W] where each pixel has a value of 0, 1, 2, 3, 4\n",
        "  # we don't care about different categories, we care just about being an object\n",
        "\n",
        "  boxes = []\n",
        "\n",
        "  for instance_number in np.unique(mask):\n",
        "    if instance_number == 0: \n",
        "      continue\n",
        "\n",
        "    Y, X = np.where(mask == instance_number)\n",
        "    box = [X.min(), Y.min(), X.max(), Y.max()]\n",
        "    boxes.append(box)\n",
        "  \n",
        "  return boxes"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlqnhKBaMsl6"
      },
      "source": [
        "# UNIT TEST\n",
        "# boxes = get_bounding_box(\"/content/vos/train/JPEGImages/2d8f5e5025/00055.jpg\", \"/content/vos/train/Annotations/2d8f5e5025/00055.png\")\n",
        "# visualize(\"/content/vos/train/JPEGImages/10b31f5431/00030.jpg\", boxes)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7om054x-N3xf"
      },
      "source": [
        "## Compute (50 * 50 * 9, 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf4SGKpQc_-J"
      },
      "source": [
        "def get_anchors_iou(image_path, label_path, anchors):\n",
        "  \n",
        "  gt_boxes = get_bounding_box(label_path)\n",
        "\n",
        "  anchors_iou = np.zeros((len(anchors), len(gt_boxes)))\n",
        "\n",
        "  for anchor_ind, anchor_box in enumerate(anchors):\n",
        "    for gt_idx, gt_box in enumerate(gt_boxes):\n",
        "      anchors_iou[anchor_ind, gt_idx] = compute_iou(anchor_box, gt_box)\n",
        "  \n",
        "  return anchors_iou    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmxMGEqhPU9k"
      },
      "source": [
        "def iou_to_label(anchors_iou):\n",
        "\n",
        "  # anchors_iou is the mutual iou of every anchor box and ground-truth box\n",
        "  # is in shape of (50 * 50 * 9, 5)\n",
        "\n",
        "  # output is in shape of (50 * 50 * 9, 1)\n",
        "\n",
        "  \"\"\"\n",
        "  a) if iou of anchor box and ground-truth box is greater than 0.7 label one is assigned\n",
        "  b) anchor box with highest iou with a specific ground-truth box is also labeled as one\n",
        "  c) iou less than 0.3 is labeled as -1\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  anchor_label = np.full((anchors_iou.shape[0], 1), fill_value=-1)\n",
        "\n",
        "\n",
        "  negative_a_idx = np.where(np.max(anchors_iou, axis=-1) < 0.3) # a rule\n",
        "  \n",
        "  positive_b_idx = np.where(np.max(anchors_iou, axis=-1) > 0.7) # b rule\n",
        "  postive_c_idx =  np.argmax(anchors_iou, axis=0) # c rule\n",
        "  \n",
        "  anchor_label[negative_a_idx, :] = 0\n",
        "\n",
        "  anchor_label[positive_b_idx, :] = 1\n",
        "  anchor_label[postive_c_idx, :] = 1\n",
        "  \n",
        "  \n",
        "  \n",
        "  return anchor_label"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GNXRcjYXKgR"
      },
      "source": [
        "# UNIT TEST\n",
        "# anchors_iou = get_anchors_iou(\"/content/image.jpg\", \"/content/label.png\", anchor_boxes)\n",
        "# anchor_label = iou_to_label(anchors_iou)\n",
        "# X1, _ = np.where(anchor_label == 1)\n",
        "# visualize(\"/content/image.jpg\", anchor_boxes[X1])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7jsq8Oz1QNn"
      },
      "source": [
        "# SANITY CHECK\n",
        "# anchors with label zero should be much higher in number than label 1 and -1\n",
        "# label 1 reasonable range is (grouth_truth, 3 * grouth_truth)\n",
        "\n",
        "# (anchor_label == -1).sum(), (anchor_label == 0).sum(), (anchor_label == 1).sum() "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AQQn2bUagSy"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aqK047McpeZ"
      },
      "source": [
        "def corner2center(box):\n",
        "\n",
        "  x1 = box[0]\n",
        "  x2 = box[2]\n",
        "\n",
        "  y1 =  box[1]\n",
        "  y2 = box[3]\n",
        "\n",
        "  center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "  width, height = (x2 - x1), (y2 - y1)\n",
        "\n",
        "  return [center_x, center_y, width, height]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiUA610LsoUL"
      },
      "source": [
        "# UNIT TEST\n",
        "# box1 = corner2center([0, 0, 5, 5]) \n",
        "# assert box1 == [2.5, 2.5, 5, 5]\n",
        "# print(\"pass!\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIKf8_wSHdxB"
      },
      "source": [
        "def center2corner(box):\n",
        "  x, y, w, h = box\n",
        "  x1 = x - (1/2) * w\n",
        "  y1 = y - (1/2) * h\n",
        "  x2 = x + (1/2) * w\n",
        "  y2 = y + (1/2) * h\n",
        "\n",
        "  return [x1, y1, x2, y2]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfhaTwsIfG1X"
      },
      "source": [
        "# UNIT TEST\n",
        "# box1 = center2corner([2.5, 2.5, 5, 5]) \n",
        "# assert box1 == [0, 0, 5, 5]\n",
        "# print(\"pass!\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps-OV-DOt54Z"
      },
      "source": [
        "$$ t_x = \\frac{A_x - G_x}{A_w} $$\n",
        "\\\n",
        "$$ t_w = \\log{\\frac{G_w}{A_w}} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8ONJ1wPdG_l"
      },
      "source": [
        "from math import log\n",
        "\n",
        "def get_parameterized_target(anchor_box, gt_box):\n",
        "  \n",
        "  # input is anchor_box, gt_box in center format\n",
        "  # output is t_X, t_y, t_h, t_w\n",
        "  A_x, A_y, A_w, A_h = anchor_box\n",
        "  G_x, G_y, G_w, G_h = gt_box\n",
        "\n",
        "  t_x = (A_x - G_x) / A_w\n",
        "  t_y = (A_y - G_y) / A_h\n",
        "  t_w = log(G_w / A_w)\n",
        "  t_h = log(G_h / A_h)\n",
        "\n",
        "  return [t_x, t_y, t_w, t_h] "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LabosgWeCJ9"
      },
      "source": [
        "# UNIT TEST\n",
        "# box1 = corner2center([0., 0., 5., 5.])\n",
        "# box2 = corner2center([2.5, 2.5, 7.5, 7.5])\n",
        "\n",
        "# assert (get_parameterized_target(box1, box2) == [-1/2, -1/2, 0, 0]) # expected output [-1/2, -1/2, 0, 0]\n",
        "# print(\"pass!\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIpCuNVytn7l"
      },
      "source": [
        "def parametrized_to_corner(t_x, t_y, t_w, t_h, anchor_box):\n",
        "  # anchor_box in format center\n",
        "  A_x, A_y, A_w, A_h = anchor_box\n",
        "  \n",
        "  pred_x = A_x - t_x * A_w  \n",
        "  pred_y = A_y - t_y * A_h\n",
        "\n",
        "  pred_w = np.exp(t_w) * A_w  \n",
        "  pred_h = np.exp(t_h) * A_h\n",
        "\n",
        "  return center2corner([pred_x, pred_y, pred_w, pred_h])  "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq0h9DQhtgK9"
      },
      "source": [
        "# UNIT TEST\n",
        "# box1 = corner2center([0., 0., 5., 5.])\n",
        "# box2 = corner2center([2.5, 2.5, 7.5, 7.5])\n",
        "\n",
        "# assert (parametrized_to_corner(*[-1/2, -1/2, 0, 0], box1) == center2corner(box2))\n",
        "# print(\"pass!\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUVyPrl7v0YW"
      },
      "source": [
        "## RPN Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZj9JIaUwb3w"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import vgg16\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRMdlbjaBqxs"
      },
      "source": [
        "feature_extractor = vgg16(pretrained=True).features[:30].to(device)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6LYekcEwRGU"
      },
      "source": [
        "class RPN(nn.Module):\n",
        "  \n",
        "  def __init__(self, n_anchors):\n",
        "    \n",
        "    super(RPN, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "    self.conv1.weight.data.normal_(0, 0.01)\n",
        "    self.conv1.bias.data.zero_()\n",
        "\n",
        "    self.cls_layer = nn.Conv2d(512, n_anchors * 2, 1, 1, 0)\n",
        "    self.cls_layer.weight.data.normal_(0, 0.01)\n",
        "    self.cls_layer.bias.data.zero_()\n",
        "\n",
        "    self.reg_layer = nn.Conv2d(512, n_anchors * 4, 1, 1, 0)\n",
        "    self.cls_layer.weight.data.normal_(0, 0.01)\n",
        "    self.cls_layer.bias.data.zero_()\n",
        "\n",
        "  def forward(self, x):\n",
        "    \n",
        "    x = self.conv1(x)\n",
        "\n",
        "    pred_cls = self.cls_layer(x)\n",
        "    pred_loc = self.reg_layer(x)\n",
        "\n",
        "    return pred_cls, pred_loc"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vulkuystU9Ry"
      },
      "source": [
        "class Faster_RCNN(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "    super(Faster_RCNN, self).__init__()\n",
        "    n_anchors = 9\n",
        "    self.rpn = RPN(n_anchors).to(device)\n",
        "\n",
        "    self.adaptive_max_pool = nn.AdaptiveMaxPool2d((7, 7))\n",
        "\n",
        "    self.roi_head_classifier = nn.Sequential(\n",
        "      nn.Linear(255088, 4096),\n",
        "      nn.Linear(4096, 4096)\n",
        "    )\n",
        "\n",
        "    self.score = nn.Linear(4096, 21)\n",
        "    self.cls_loc = nn.Linear(4096, 21 * 4)\n",
        "\n",
        "\n",
        "  def forward(self, x, indices_and_rois):\n",
        "    \n",
        "    pred_cls, pred_loc = self.rpn(x)\n",
        "\n",
        "    # pre-process for faster_rcnn\n",
        "    # pred_cls, pred_loc = rpn(output_map) # output should be (1, 9 * 2, 50 , 50), (1, 9 * 4, 50, 50)\n",
        "\n",
        "    pred_loc = pred_loc.contiguous().view(-1, 4)\n",
        "    # pred_cls = pred_cls.permute(0, 2, 3, 1).contiguous().view(1, 50, 50, 18)\n",
        "    objectness_score = pred_cls.view(50 * 50, 9, 2)[:, :, :, 1].contiguous().view(-1, 1)\n",
        "    pred_cls = pred_cls.view(-1, 2)\n",
        "\n",
        "    pred_loc_corner = get_pred_loc_corner(pred_loc) # (22500, 4) corner format\n",
        "    pred_loc_corner = clip_into_image(pred_loc_corner) # clip boxes into the height and width of image\n",
        "    pred_high_loc_corner = get_high_score(objectness_score, pred_loc_corner) # (12000, 4)\n",
        "    pred_nms_loc_corner = NMS(pred_high_loc_corner) # (2000, 4)\n",
        "    roi_labels, roi_loc, gt_index = get_roi_sample(image_path, label_path, pred_nms_loc_corner) # (128, 1) (128, 4)\n",
        "\n",
        "    image_index = torch.zeros((len(roi_loc), 1))\n",
        "    roi_loc = torch.from_numpy(roi_loc)\n",
        "    indices_and_rois = torch.cat((image_index, roi_loc), dim=1)\n",
        "\n",
        "    gt_boxes = get_bounding_box(label_path)\n",
        "    roi_loc_parametrized = np.zeros_like(roi_loc)\n",
        "\n",
        "    for idx, roi in enumerate(roi_loc):\n",
        "      gt_box = gt_boxes[gt_index[idx]]  \n",
        "      roi_parametrized[idx] = get_parameterized_target(roi, gt_box)\n",
        "\n",
        "\n",
        "  # roi_parametrized (128, 4)\n",
        "  # roi_labels (128, 1)\n",
        "\n",
        "    # (1, 512, 50, 50)\n",
        "    output = []\n",
        "\n",
        "    for idx, roi in enumerate(indices_and_rois):\n",
        "      \n",
        "      image_index, x1, y1, x2, y2 = roi\n",
        "\n",
        "      x1, y1, x2, y2 = x1 // 16, x2 // 16, y1 // 16, y2 // 16\n",
        "      \n",
        "      im = x.narrow(0, 0, 1)[..., y1:y2, x1:x2]\n",
        "\n",
        "      output.append(self.adaptive_max_pool(im)) # (512, 7, 7)\n",
        "\n",
        "\n",
        "    output = torch.cat(output, 0)\n",
        "    output = output.view(128, -1) # (128, 255088)\n",
        "    \n",
        "    output = self.roi_head_classifier(output)\n",
        "    pred_roi_cls_score = self.score(output)\n",
        "    pred_roi_loc = self.cls_loc(output)\n",
        "\n",
        "    return pred_cls, pred_loc, pred_roi_cls_score, pred_roi_loc, roi_labels, roi_parametrized "
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H18lOMebw5Nw"
      },
      "source": [
        "# n_anchors = len(scales) * len(ratios)\n",
        "# n_anchors = 9\n",
        "# rpn = RPN(n_anchors).to(device)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Dscff0IzsdN"
      },
      "source": [
        "# UNIT Test\n",
        "# assert (rpn.feature_extractor(torch.randn(4, 3, 800, 800)).shape) == (4, 512, 50, 50), \"something wrong with feature extractor output shape!\""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gtPEwWobJ1V"
      },
      "source": [
        "## NMS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMqETyd7Mj2U"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def NMS(boxes):\n",
        "  # boxes in order of the objectness score\n",
        "  boxes_detected = []\n",
        "  boxes_remained = np.copy(boxes)\n",
        "\n",
        "  while len(boxes_remained) > 0:\n",
        "    \n",
        "    box_detected = boxes_remained[0]\n",
        "    boxes_detected.append(box_detected)\n",
        "    \n",
        "    boxes_remained = boxes_remained[1:]\n",
        "\n",
        "    mask = np.ones(len(boxes_remained), dtype=bool)\n",
        "    idx_to_remove = []\n",
        "    \n",
        "    for idx, box in enumerate(boxes_remained):\n",
        "      \n",
        "      if compute_iou(box_detected, box) > 0.7:\n",
        "        idx_to_remove.append(idx)\n",
        "    \n",
        "    boxes_remained = boxes_remained[mask, ...]\n",
        "  \n",
        "  return boxes_detected[:2000]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7haPYHrMmbP"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEdWuzYoNeWh"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "import glob\n",
        "import os"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlGW7bCxztn2"
      },
      "source": [
        "anchor_boxes = generate_all_anchor_boxes()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk7oV7fNNjjO"
      },
      "source": [
        "class VOS(Dataset):\n",
        "\n",
        "  def __init__(self, root):\n",
        "    self.images = np.array(glob.glob(os.path.join(root, \"JPEGImages/*/*.jpg\")))[:2000]\n",
        "    self.root = root\n",
        "\n",
        "    idx_to_keep = []\n",
        "    print(\"Removing images with no GT-box\")\n",
        "    for idx, image_path in enumerate(tqdm(self.images)):\n",
        "      \n",
        "      image_name = image_path.split(\"/\")[-1].split(\".\")[0]\n",
        "      folder_id = image_path.split(\"/\")[-2]\n",
        "      label_path = os.path.join(self.root, \"Annotations\", folder_id, image_name + \".png\")\n",
        "      \n",
        "      number_of_instances = get_number_of_instances(label_path)\n",
        "      if number_of_instances > 1:\n",
        "        idx_to_keep.append(idx)\n",
        "\n",
        "    \n",
        "    self.images = self.images[idx_to_keep]\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    image_path = self.images[idx]\n",
        "    \n",
        "    image_name = image_path.split(\"/\")[-1].split(\".\")[0]\n",
        "    folder_id = image_path.split(\"/\")[-2]\n",
        "    label_path = os.path.join(self.root, \"Annotations\", folder_id, image_name + \".png\")\n",
        "\n",
        "\n",
        "    iou = get_anchors_iou(image_path, label_path, anchor_boxes)\n",
        "\n",
        "    highest_iou = np.argmax(iou, axis=-1) # only GT-box with highest IoU is considered\n",
        "    gt_boxes = get_bounding_box(label_path)\n",
        "\n",
        "    # for each anchor box we have (t_x, t_y, t_w, t_h)\n",
        "    # ground truth box with highest iou is chosen\n",
        "    loc = np.zeros((len(anchor_boxes), 4)) \n",
        "    label = iou_to_label(iou)\n",
        "    \n",
        "    # ignore anchor boxes outside the image\n",
        "    valid_indexes = get_valid_anchor_boxes(anchor_boxes)\n",
        "    label[~valid_indexes] = -1\n",
        "\n",
        "    # sampling positive and negative anchor boxes with ratio 1:1 (if possible)\n",
        "    pos_index = np.where(label == 1)[0]\n",
        "    disable = np.random.choice(pos_index, size=max(0, len(pos_index) - 128), replace=False)\n",
        "    label[disable] = -1\n",
        "\n",
        "    neg_index = np.where(label == 0)[0]\n",
        "    pos_count = np.sum(label == 1)\n",
        "    disable = np.random.choice(neg_index, size=len(neg_index) - (n_sample - pos_count), replace=False)\n",
        "    label[disable] = -1\n",
        "\n",
        "\n",
        "    for anchor_idx in range((len(anchor_boxes))):\n",
        "      \n",
        "      anchor_center = corner2center(anchor_boxes[anchor_idx]) \n",
        "      gt_center = corner2center(gt_boxes[highest_iou[anchor_idx]]) # coordination of nearest GT-box\n",
        "\n",
        "      loc[anchor_idx] = get_parameterized_target(anchor_center, gt_center)\n",
        "\n",
        "   \n",
        "    image_file = Image.open(image_path)\n",
        "    image_file = image_file.resize((800, 800))\n",
        "    image_tensor = transforms.ToTensor()((np.array(image_file)))\n",
        "\n",
        "    return image_path, label_path, image_tensor, label, loc"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYhBjrIlwBjN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "72de22c7e1414d4d9f43ed98f3a5c819",
            "3c8e5cc37f2c414685a8f9b7786c710b",
            "35fbeb4ab281469386df3e404d2d9661",
            "6ffd56f46f3a479db197899674ea3b86",
            "f6183bd884884b578858c80198156ec5",
            "850dd669787d442796b72f4ed26dd59b",
            "f264973b7b2742739b9beabe8046e255",
            "4b9d08ba5eb14d0bbb55a562dbdadd75",
            "a7feba3239364f5a879a2782a1f9eec8",
            "fa7f305001044c7dab15d49a8d80f6fd",
            "e91946182793490a8499da8f1d5ec34c"
          ]
        },
        "outputId": "eb25bb9d-fbb1-41f6-d3c8-4f7412b8eb1a"
      },
      "source": [
        "vos = VOS(\"/content/vos/train\")\n",
        "train_loader = DataLoader(vos, batch_size=batch_size, shuffle=True)\n",
        "len(train_loader)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing images with no GT-box\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72de22c7e1414d4d9f43ed98f3a5c819",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1979"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5XFb6L7Pg00"
      },
      "source": [
        "# vos = VOS(\"/content/vos/train\")\n",
        "# image_file, label, loc = vos[0]\n",
        "\n",
        "# # Sanity Check\n",
        "# image_file.shape, label.shape, loc.shape\n",
        "# print((label == 0).sum())\n",
        "# print((label == 1).sum())\n",
        "\n",
        "# # UNIT TEST\n",
        "# (label == 0).sum() + (label == 1).sum() == n_sample"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9f4D1TfhQX4"
      },
      "source": [
        "# image_tensor, label, loc = next(iter(train_loader))\n",
        "# image_tensor.shape, label.shape, loc.shape"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYki6lDX9aPY"
      },
      "source": [
        "## Post Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x89bN6i4ZZo"
      },
      "source": [
        "$$ t_x = \\frac{A_x - G_x}{A_w} $$\n",
        "\\\n",
        "$$ t_w = \\log{\\frac{G_w}{A_w}} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GUhgGX9CTUI"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l4bO2c23HmU"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def get_pred_loc_corner(pred_loc):\n",
        "\n",
        "  pred_location_convert = np.zeros_like(pred_loc)\n",
        "\n",
        "\n",
        "  for idx, pred in enumerate(tqdm(pred_loc)):\n",
        "    A_x, A_y, A_w, A_h = corner2center(anchor_boxes[idx])\n",
        "    t_x, t_y, t_w, t_h = pred\n",
        "\n",
        "    x1, y1, x2, y2 = parametrized_to_corner(t_x, t_y, t_w, t_h, [A_x, A_y, A_w, A_h])\n",
        "\n",
        "    pred_location_convert[idx] = [x1, y1, x2, y2]\n",
        "  \n",
        "\n",
        "  return pred_location_convert\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFtmE4lJ9nOg"
      },
      "source": [
        "## Clip to the Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKILjat99o9M"
      },
      "source": [
        "def clip_into_image(boxes):\n",
        "  \n",
        "  boxes[:, 0] = np.clip(boxes[:, 0], 0 + 5, 800-5)\n",
        "  boxes[:, 1] = np.clip(boxes[:, 1], 0 + 5, 800-5)\n",
        "  boxes[:, 2] = np.clip(boxes[:, 2], 0 + 5, 800-5)\n",
        "  boxes[:, 3] = np.clip(boxes[:, 2], 0 + 5, 800-5)\n",
        "\n",
        "  return boxes"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQXJ7qyTBgnU"
      },
      "source": [
        "## Sort Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIgU-zQbBh0J"
      },
      "source": [
        "def get_high_score(objectness_score, pred_loc):\n",
        "\n",
        "  order = objectness_score.ravel().argsort(descending=True)\n",
        "  pred_ordered = pred_loc[order[:12000], :]\n",
        "  \n",
        "  return pred_ordered"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3icfGh07HMX"
      },
      "source": [
        "# pred_nms = NMS(pred_ordered) # (2000, 4) region proposal in format (x1, y1, x2, y2)\n",
        "# pred_nms.shape "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfCGzRszklM0"
      },
      "source": [
        "## Preparation for Faster R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpSvma60TJA"
      },
      "source": [
        "## Sampling ROIs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbOKxt22-1n7"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qqdUJzTkmbW"
      },
      "source": [
        "def get_roi_sample(image_path, label_path, ROIs):\n",
        "  \n",
        "  anchors_iou = get_anchors_iou(image_path, label_path, ROI) # (2000, 5)\n",
        "  \n",
        "  max_iou = np.max(anchors_iou, axis=-1)\n",
        "  \n",
        "  gt_index = np.argmax(anchors_iou, axis=-1) # (2000, 1)\n",
        "\n",
        "  pos_labels = np.where(max_iou > 0.5)[0]\n",
        "\n",
        "  neg_labels = np.where((max_iou > 0.1) & (max_iou < 0.5))[0]\n",
        "\n",
        "  positive_labels = np.random.choice(pos_labels, size=min(len(pos_labels), 32), replace=False)\n",
        "  negative_labels = np.random.choice(neg_labels, size=min(len(neg_labels), 96), replace=False)\n",
        "\n",
        "  sample_index = np.append(positive_labels, negative_labels)\n",
        "  labels = np.zeros(128)\n",
        "  labels[:32] = 1\n",
        "\n",
        "  return labels, ROI[sample_index], gt_index[sample_index]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-tJngL8EZIE"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qrrm9ggTSXG"
      },
      "source": [
        "faster_rcnn = Faster_RCNN().to(device)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xosVwz3fXMog"
      },
      "source": [
        "faster_rcnn_optim = torch.optim.Adam(faster_rcnn.parameters(), lr=0.001)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuWQkg4tMoR7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317,
          "referenced_widgets": [
            "001b43024ae84c38a9f3ee68b586b532",
            "25de0b87967d4ea4896cf6fb28b1525e",
            "91cfcde298854d62a0eab84c06c9de7d",
            "b262a09a985448df90d1b0e107278895",
            "55b2afaf15da4ecf821503e82118f6c2",
            "eb8bc3554656456d9c77afb7afbe9d6d",
            "6e7600704af44425879a084f3a145931",
            "708ad591c8bd473d8eb252453ec9d2db",
            "aaf1031a89ae431db5853f1077d19ffb",
            "9349dbceabe2447595fae8232be871a3",
            "7b4fbc393ae94a1b97bd43927a8af9a7"
          ]
        },
        "outputId": "4eb0dd2b-180c-4264-f8de-9f5d9d5c0377"
      },
      "source": [
        "regression_loss_acc = []\n",
        "classification_loss_acc = []\n",
        "\n",
        "for iteration, (image_path, mask_path, image, cls, loc)  in enumerate(tqdm(train_loader)):\n",
        "  # image in shape of (1, 3, 800, 800)\n",
        "  # cls in shape of (1, 22500, 1)\n",
        "  # loc in shape of (1, 22500, 4)\n",
        "\n",
        "  cls = cls[0].reshape(-1).to(device)\n",
        "  loc = loc[0].to(device)\n",
        "  image = image.to(device)\n",
        "  output_map = feature_extractor(image).detach()\n",
        "\n",
        "  faster_rcnn_optim.zero_grad()\n",
        "\n",
        "  pred_cls, pred_loc, pred_roi_cls_score, pred_roi_loc, roi_labels, roi_parametrized = faster_rcnn_optim = faster_rcnn(output_map)\n",
        "\n",
        "\n",
        "  classification_loss = F.cross_entropy(pred_cls, cls, ignore_index=-1)\n",
        "  \n",
        "  # classification_loss_acc.append(classification_loss.item())\n",
        "  print(classification_loss.item())\n",
        "\n",
        "  pos_index = torch.where(cls == 1)\n",
        "  x = torch.abs(pred_loc[pos_index] - loc[pos_index])\n",
        "\n",
        "  regression_loss = (x < 1).float() * (0.5) * (x**2) + (x > 1).float() * (x - 0.5)\n",
        "  regression_loss = regression_loss.sum()\n",
        "  regression_loss = regression_loss / (len(pos_index))\n",
        "\n",
        "  regression_loss_acc.append(regression_loss.item())\n",
        "  print(regression_loss.item())\n",
        "\n",
        "  rpn_loss = classification_loss + (10 * regression_loss)\n",
        "\n",
        "\n",
        "  ### Faster R-CNN\n",
        "  roi_cls_loss = F.cross_entropy(pred_roi_cls_score, roi_labels, ignore_index=-1)\n",
        "\n",
        "  pred_roi_loc = pred_roi_loc[torch.arange(0, 128).long(), 1] # (128, 4)\n",
        "\n",
        "  pred_roi_loc = torch.randn((128, 21, 4))\n",
        "  pred_loc = pred_loc[torch.arange(0, 128).long(), 1]\n",
        "\n",
        "  x = torch.abs(pred_loc - roi_parametrized)\n",
        "  roi_reg_loss = (x < 1).float() * 0.5 * (x**2) + (x >= 1).float() * (x - 0.5)\n",
        "  roi_reg_loss = roi_reg_loss.sum() / len(roi_parametrized.shape[0])\n",
        "  \n",
        "  faster_rcnn_loss = roi_cls_loss + (10 * roi_reg_loss) \n",
        "  \n",
        "  loss = rpn_loss + faster_rcnn_loss\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optim.step()\n",
        "\n",
        "  if iteration % 100 == 0:\n",
        "    \n",
        "    # visualize 100 high score box\n",
        "    obj_score = pred_cls[:, 1] # [22500, 2]\n",
        "    \n",
        "    order_index = obj_score.argsort(dim=0)[:12000]\n",
        "    predicted_boxes = pred_loc[order_index].detach().cpu().numpy()\n",
        "    for idx, pred_box in enumerate(predicted_boxes):\n",
        "      anchor_box = anchor_boxes[order_index[idx]]\n",
        "      predicted_boxes[idx] = parametrized_to_corner(*pred_box, anchor_box)\n",
        "\n",
        "    predicted_boxes = clip_into_image(predicted_boxes)\n",
        "    detected_boxes = NMS(predicted_boxes) #[22500, 4]\n",
        "    print(len(detected_boxes))\n",
        "    # print(image_path)\n",
        "    visualize(image_path[0], detected_boxes, get_bounding_box(mask_path[0]))\n",
        "\n",
        "    print(\"classification loss: \", np.mean(classification_loss_acc[-100:]))\n",
        "    print(\"regression loss:\", np.mean(regression_loss_acc[-100:]))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "001b43024ae84c38a9f3ee68b586b532",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1979 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-98c3a4a95bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0moutput_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mpred_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# output should be (1, 9 * 2, 50 , 50), (1, 9 * 4, 50, 50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optim' is not defined"
          ]
        }
      ]
    }
  ]
}